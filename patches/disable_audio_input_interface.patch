diff --git a/modules/audio_device/audio_device_impl.cc b/modules/audio_device/audio_device_impl.cc
index c63a478c5f..e85fac074e 100644
--- a/modules/audio_device/audio_device_impl.cc
+++ b/modules/audio_device/audio_device_impl.cc
@@ -241,6 +241,7 @@ int32_t AudioDeviceModuleImpl::CreatePlatformSpecificObjects(
     audio_device_ = std::make_unique<ios_adm::AudioDeviceIOS>(
         env,
         /*bypass_voice_processing=*/false,
+        /*disable_audio_input=*/false,
         /*muted_speech_event_handler=*/nullptr,
         /*render_error_handler=*/nullptr);
     RTC_LOG(LS_INFO) << "iPhone Audio APIs will be utilized.";
diff --git a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h
index abfa679a1c..6037318d32 100644
--- a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h
+++ b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h
@@ -41,6 +41,10 @@ RTC_OBJC_EXPORT
 /* Initialize object with default H264 video encoder/decoder factories and default ADM */
 - (instancetype)init;
 
+/* Initialize object with default H264 video encoder/decoder factories and default ADM
+ specified whether to disable audio input */
+- (instancetype)initWithDisableAudioInput:(BOOL)disableAudioInput;
+
 /* Initialize object with injectable video encoder/decoder factories and default
  * ADM */
 - (instancetype)
diff --git a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm
index 5df145e34a..d001664628 100644
--- a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm
+++ b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm
@@ -58,6 +58,7 @@ @implementation RTC_OBJC_TYPE (RTCPeerConnectionFactory) {
   std::unique_ptr<webrtc::Thread> _workerThread;
   std::unique_ptr<webrtc::Thread> _signalingThread;
   BOOL _hasStartedAecDump;
+  BOOL _disableAudioInput;
 }
 
 @synthesize nativeFactory = _nativeFactory;
@@ -74,7 +75,8 @@ - (instancetype)init {
       [[RTC_OBJC_TYPE(RTCVideoDecoderFactoryH264) alloc] init]);
   dependencies.env = webrtc::CreateEnvironment();
 #ifdef WEBRTC_IOS
-  dependencies.adm = webrtc::CreateAudioDeviceModule(*dependencies.env);
+  dependencies.adm = webrtc::CreateAudioDeviceModule(
+      *dependencies.env, false, _disableAudioInput);
 #endif
   return [self initWithMediaAndDependencies:dependencies];
 }
@@ -89,6 +91,11 @@ - (instancetype)init {
                           audioDevice:nil];
 }
 
+- (instancetype)initWithDisableAudioInput:(BOOL)disableAudioInput {
+  _disableAudioInput = disableAudioInput;
+  return [self init];
+}
+
 - (instancetype)
     initWithEncoderFactory:
         (nullable id<RTC_OBJC_TYPE(RTCVideoEncoderFactory)>)encoderFactory
diff --git a/sdk/objc/native/api/audio_device_module.h b/sdk/objc/native/api/audio_device_module.h
index 5a8944c674..3a80c39bfd 100644
--- a/sdk/objc/native/api/audio_device_module.h
+++ b/sdk/objc/native/api/audio_device_module.h
@@ -27,11 +27,12 @@ namespace webrtc {
 // most scenarios.
 scoped_refptr<AudioDeviceModule> CreateAudioDeviceModule(
     const Environment& env,
-    bool bypass_voice_processing = false);
+    bool bypass_voice_processing = false,
+    bool disable_audio_input = false);
 
 [[deprecated("Pass `env` explicitly instead of relying on the default")]]
 scoped_refptr<AudioDeviceModule> CreateAudioDeviceModule(
-    bool bypass_voice_processing = false);
+    bool bypass_voice_processing = false, bool disable_audio_input = false);
 
 // If `muted_speech_event_handler` is exist, audio unit will catch speech
 // activity while muted.
diff --git a/sdk/objc/native/api/audio_device_module.mm b/sdk/objc/native/api/audio_device_module.mm
index 8325179c94..99088a71c2 100644
--- a/sdk/objc/native/api/audio_device_module.mm
+++ b/sdk/objc/native/api/audio_device_module.mm
@@ -23,21 +23,25 @@
 namespace webrtc {
 
 scoped_refptr<AudioDeviceModule> CreateAudioDeviceModule(
-    const Environment& env, bool bypass_voice_processing) {
+    const Environment& env,
+    bool bypass_voice_processing,
+    bool disable_audio_input) {
   RTC_DLOG(LS_INFO) << __FUNCTION__;
   return make_ref_counted<ios_adm::AudioDeviceModuleIOS>(
       env,
       bypass_voice_processing,
+      disable_audio_input,
       /*muted_speech_event_handler=*/nullptr,
       /*error_handler=*/nullptr);
 }
 
 scoped_refptr<AudioDeviceModule> CreateAudioDeviceModule(
-    bool bypass_voice_processing) {
+    bool bypass_voice_processing, bool disable_audio_input) {
   RTC_DLOG(LS_INFO) << __FUNCTION__;
   return make_ref_counted<ios_adm::AudioDeviceModuleIOS>(
       CreateEnvironment(),
       bypass_voice_processing,
+      disable_audio_input,
       /*muted_speech_event_handler=*/nullptr,
       /*error_handler=*/nullptr);
 }
@@ -49,7 +53,11 @@
     bool bypass_voice_processing) {
   RTC_DLOG(LS_INFO) << __FUNCTION__;
   return make_ref_counted<ios_adm::AudioDeviceModuleIOS>(
-      env, bypass_voice_processing, muted_speech_event_handler, error_handler);
+      env,
+      bypass_voice_processing,
+      false,
+      muted_speech_event_handler,
+      error_handler);
 }
 
 scoped_refptr<AudioDeviceModule> CreateMutedDetectAudioDeviceModule(
@@ -60,6 +68,7 @@
   return make_ref_counted<ios_adm::AudioDeviceModuleIOS>(
       CreateEnvironment(),
       bypass_voice_processing,
+      false,
       muted_speech_event_handler,
       error_handler);
 }
diff --git a/sdk/objc/native/src/audio/audio_device_ios.h b/sdk/objc/native/src/audio/audio_device_ios.h
index 7dcffb07d5..4fb81c8ee2 100644
--- a/sdk/objc/native/src/audio/audio_device_ios.h
+++ b/sdk/objc/native/src/audio/audio_device_ios.h
@@ -59,6 +59,7 @@ class AudioDeviceIOS : public AudioDeviceGeneric,
   explicit AudioDeviceIOS(
       const Environment& env,
       bool bypass_voice_processing,
+      bool disable_audio_input,
       AudioDeviceModule::MutedSpeechEventHandler muted_speech_event_handler,
       AudioDeviceIOSRenderErrorHandler render_error_handler);
   ~AudioDeviceIOS() override;
@@ -227,6 +228,9 @@ class AudioDeviceIOS : public AudioDeviceGeneric,
   // Determines whether voice processing should be enabled or disabled.
   const bool bypass_voice_processing_;
 
+  // Whether to force disable audio input.
+  const bool disable_audio_input_;
+
   // Handle a user speaking during muted event
   AudioDeviceModule::MutedSpeechEventHandler muted_speech_event_handler_;
 
diff --git a/sdk/objc/native/src/audio/audio_device_ios.mm b/sdk/objc/native/src/audio/audio_device_ios.mm
index 53dec77c75..0698f9ebcf 100644
--- a/sdk/objc/native/src/audio/audio_device_ios.mm
+++ b/sdk/objc/native/src/audio/audio_device_ios.mm
@@ -98,10 +98,12 @@ static void LogDeviceInfo() {
 AudioDeviceIOS::AudioDeviceIOS(
     const Environment& env,
     bool bypass_voice_processing,
+    bool disable_audio_input,
     AudioDeviceModule::MutedSpeechEventHandler muted_speech_event_handler,
     AudioDeviceIOSRenderErrorHandler render_error_handler)
     : env_(env),
       bypass_voice_processing_(bypass_voice_processing),
+      disable_audio_input_(disable_audio_input),
       muted_speech_event_handler_(muted_speech_event_handler),
       render_error_handler_(render_error_handler),
       disregard_next_render_error_(false),
@@ -822,8 +824,10 @@ static void LogDeviceInfo() {
     return false;
   }
   BOOL detect_mute_speech_ = (muted_speech_event_handler_ != 0);
-  audio_unit_.reset(new VoiceProcessingAudioUnit(
-      bypass_voice_processing_, detect_mute_speech_, this));
+  audio_unit_.reset(new VoiceProcessingAudioUnit(bypass_voice_processing_,
+                                                 detect_mute_speech_,
+                                                 disable_audio_input_,
+                                                 this));
   if (!audio_unit_->Init()) {
     audio_unit_.reset();
     return false;
diff --git a/sdk/objc/native/src/audio/audio_device_module_ios.h b/sdk/objc/native/src/audio/audio_device_module_ios.h
index 5ff50621b3..cbde002d46 100644
--- a/sdk/objc/native/src/audio/audio_device_module_ios.h
+++ b/sdk/objc/native/src/audio/audio_device_module_ios.h
@@ -32,6 +32,7 @@ class AudioDeviceModuleIOS : public AudioDeviceModule {
   explicit AudioDeviceModuleIOS(
       const Environment& env,
       bool bypass_voice_processing,
+      bool disable_audio_input,
       MutedSpeechEventHandler muted_speech_event_handler,
       ADMErrorHandler error_handler);
   ~AudioDeviceModuleIOS() override;
@@ -140,6 +141,7 @@ class AudioDeviceModuleIOS : public AudioDeviceModule {
 
   const Environment env_;
   const bool bypass_voice_processing_;
+  const bool disable_audio_input_;
   MutedSpeechEventHandler muted_speech_event_handler_;
   ADMErrorHandler error_handler_;
   bool initialized_ = false;
diff --git a/sdk/objc/native/src/audio/audio_device_module_ios.mm b/sdk/objc/native/src/audio/audio_device_module_ios.mm
index 7420d05ebd..8a77d7fcac 100644
--- a/sdk/objc/native/src/audio/audio_device_module_ios.mm
+++ b/sdk/objc/native/src/audio/audio_device_module_ios.mm
@@ -46,10 +46,12 @@
 AudioDeviceModuleIOS::AudioDeviceModuleIOS(
     const Environment& env,
     bool bypass_voice_processing,
+    bool disable_audio_input,
     MutedSpeechEventHandler muted_speech_event_handler,
     ADMErrorHandler error_handler)
     : env_(env),
       bypass_voice_processing_(bypass_voice_processing),
+      disable_audio_input_(disable_audio_input),
       muted_speech_event_handler_(muted_speech_event_handler),
       error_handler_(error_handler) {
   RTC_LOG(LS_INFO) << "current platform is IOS";
@@ -95,6 +97,7 @@
   audio_device_ =
       std::make_unique<ios_adm::AudioDeviceIOS>(env_,
                                                 bypass_voice_processing_,
+                                                disable_audio_input_,
                                                 muted_speech_event_handler_,
                                                 error_handler);
   RTC_CHECK(audio_device_);
diff --git a/sdk/objc/native/src/audio/voice_processing_audio_unit.h b/sdk/objc/native/src/audio/voice_processing_audio_unit.h
index 99586a94ed..b2dab417e4 100644
--- a/sdk/objc/native/src/audio/voice_processing_audio_unit.h
+++ b/sdk/objc/native/src/audio/voice_processing_audio_unit.h
@@ -53,6 +53,7 @@ class VoiceProcessingAudioUnit {
  public:
   VoiceProcessingAudioUnit(bool bypass_voice_processing,
                            bool detect_mute_speech,
+                           bool disable_audio_input,
                            VoiceProcessingAudioUnitObserver* observer);
   ~VoiceProcessingAudioUnit();
 
@@ -141,6 +142,7 @@ class VoiceProcessingAudioUnit {
 
   const bool bypass_voice_processing_;
   const bool detect_mute_speech_;
+  const bool disable_audio_input_;
   VoiceProcessingAudioUnitObserver* observer_;
   AudioUnit vpio_unit_;
   VoiceProcessingAudioUnit::State state_;
diff --git a/sdk/objc/native/src/audio/voice_processing_audio_unit.mm b/sdk/objc/native/src/audio/voice_processing_audio_unit.mm
index 066f3b161c..430a70a688 100644
--- a/sdk/objc/native/src/audio/voice_processing_audio_unit.mm
+++ b/sdk/objc/native/src/audio/voice_processing_audio_unit.mm
@@ -76,9 +76,11 @@ static OSStatus GetAGCState(AudioUnit audio_unit, UInt32* enabled) {
 VoiceProcessingAudioUnit::VoiceProcessingAudioUnit(
     bool bypass_voice_processing,
     bool detect_mute_speech,
+    bool disable_audio_input,
     VoiceProcessingAudioUnitObserver* observer)
     : bypass_voice_processing_(bypass_voice_processing),
       detect_mute_speech_(detect_mute_speech),
+      disable_audio_input_(disable_audio_input),
       observer_(observer),
       vpio_unit_(nullptr),
       state_(kInitRequired) {
@@ -116,8 +118,8 @@ static OSStatus GetAGCState(AudioUnit audio_unit, UInt32* enabled) {
     return false;
   }
 
-  // Enable input on the input scope of the input element.
-  UInt32 enable_input = 1;
+  // If audio input not disabled, enable input on the input scope of the input element.
+  UInt32 enable_input = disable_audio_input_ ? 0 : 1;
   result = AudioUnitSetProperty(vpio_unit_,
                                 kAudioOutputUnitProperty_EnableIO,
                                 kAudioUnitScope_Input,
